{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Anna C Helfeld C\n",
    "# Fall 2018-Winter 2019\n",
    "\n",
    "# This code uses my solutions written in Octave/Matlab as a guide\n",
    "# Machine Learning (Andrew Ng class on Coursera)\n",
    "# Homework 4: Neural Networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pandas import *\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy import optimize\n",
    "import math as mth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"From scratch\" neural network - not using MLPClassifier; see HW3 for that implementation\n",
    "# X contains pixel data of handwritten digits\n",
    "# y contains digit class (1, 2, 3, etc.)\n",
    "\n",
    "# Make sure file exists\n",
    "import os  \n",
    "os.path.isfile('./ex4data1.mat')    # True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ...,\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "import h5py \n",
    "digitfile = sio.loadmat('ex4data1.mat') \n",
    "digitfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put X and y data into arrays\n",
    "Xdata = digitfile['X']\n",
    "ydata = digitfile['y']\n",
    "Alldata = np.concatenate((Xdata,ydata), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...   391  392  393  394  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "   395  396  397  398  399   400  \n",
       "0  0.0  0.0  0.0  0.0  0.0  10.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  10.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  10.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  10.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  10.0  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alldatadf = DataFrame(data=Alldata)  #Put data into data frame\n",
    "Alldatadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3379</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>-0.000993</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9   ...        391  \\\n",
       "4032  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.000000   \n",
       "2884  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.000000   \n",
       "3135  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.000000   \n",
       "3379  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  -0.001059   \n",
       "2062  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.000000   \n",
       "\n",
       "           392       393       394  395  396  397  398  399  400  \n",
       "4032  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  8.0  \n",
       "2884  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  5.0  \n",
       "3135  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  6.0  \n",
       "3379 -0.000993 -0.000343  0.000032  0.0  0.0  0.0  0.0  0.0  6.0  \n",
       "2062  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  4.0  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alldatadf_ran = Alldatadf.sample(frac=1) #randomize data\n",
    "Alldatadf_ran.head() #check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training data and cross-validation data\n",
    "Xtrain = Alldatadf_ran.iloc[0:mth.floor(Alldatadf_ran.shape[0]*0.8),0:-1]\n",
    "ytrain = Alldatadf_ran.iloc[0:mth.floor(Alldatadf_ran.shape[0]*0.8),-1]\n",
    "\n",
    "Xcv = Alldatadf_ran.iloc[mth.floor(Alldatadf_ran.shape[0]*0.8):Alldatadf_ran.shape[0],0:-1]\n",
    "ycv = Alldatadf_ran.iloc[mth.floor(Alldatadf_ran.shape[0]*0.8):Alldatadf_ran.shape[0],-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put into arrays\n",
    "Xtrain_a = Xtrain.values\n",
    "ytrain_a = ytrain.values\n",
    "Xcv_a = Xcv.values\n",
    "ycv_a = ycv.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sigmoid and sigmoid gradient functions\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def sigmoidgrad(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bias term to Xtrain_a\n",
    "Xtrain_ab = np.concatenate((np.ones((Xtrain_a.shape[0],1)),Xtrain_a),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters of neural network\n",
    "hl_size = 25 #size of hidden layer\n",
    "ol_size = 10 #size of output layer\n",
    "eps = 0.12 #range of random number initialization of theta \n",
    "numsam = ytrain_a.size #number of training examples\n",
    "lam_reg = 1 #regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize theta - the weights in the neural network\n",
    "Theta1 = np.random.uniform(low=-eps, high=eps, size=(hl_size,Xtrain_a.shape[1]+1)) #25by401\n",
    "Theta2 = np.random.uniform(low=-eps, high=eps, size=(ol_size,hl_size+1)) #10by26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Flatten Thetas and put into one 1D array\n",
    "thetas_oned = np.concatenate((Theta1.flatten(),Theta2.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 401)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the re-shape of theta1\n",
    "Theta1_test = thetas_oned[0:hl_size*(Xtrain_a.shape[1]+1)].reshape((hl_size,Xtrain_a.shape[1]+1)) \n",
    "Theta1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the re-shape of theta2\n",
    "Theta2_test = thetas_oned[hl_size*(Xtrain_a.shape[1]+1):].reshape((ol_size,hl_size+1)) \n",
    "Theta2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8., 5., 6., ..., 8., 6., 9.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_a #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for changing the form of y\n",
    "#Change to a num_samples by 10 matrix\n",
    "def reparam_y(y, ol_sz, m):\n",
    "    yn = np.zeros((y.size,ol_sz))\n",
    "    for i in range(0,m): # m = num_samples -> 4000\n",
    "        if y[i]==10:\n",
    "            yn[i,0]=1\n",
    "        else:\n",
    "            yn[i,int(y[i])]=1\n",
    "    return yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ycheckn=reparam_y(ytrain_a,ol_size,numsam)\n",
    "ycheckn #check to make sure it looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propogation cost function\n",
    "# theta1 and theta2 are the weights for the network, hl and ol are hidden and output layer size\n",
    "# m is number of samples, lam is the regularization parameter\n",
    "args = (Xtrain_ab, ytrain_a, hl_size, ol_size, numsam, lam_reg)  # parameter values\n",
    "def fpnn_cost(x, *args):\n",
    "    thetas = x\n",
    "    X, y, hl_sz, ol_sz, m, lam = args\n",
    "    \n",
    "    #Reshape thetas\n",
    "    theta1 = thetas[0:hl_sz*(X.shape[1])].reshape((hl_sz,X.shape[1]))\n",
    "    theta2 = thetas[hl_sz*(X.shape[1]):].reshape((ol_sz,hl_sz+1)) \n",
    "    \n",
    "    # Calculate layer 2\n",
    "    z2 = np.matmul(X,np.transpose(theta1)) # 4000by401 x 401by25 = 4000by25\n",
    "    a2 = sigmoid(z2) #4000by25\n",
    "    # Add bias term of ones\n",
    "    a2 = np.concatenate((np.ones((a2.shape[0],1)),a2),axis=1) #4000by1 conc 4000by25 -> 4000by26\n",
    "    #Calculate layer 3\n",
    "    z3 = np.matmul(a2,np.transpose(theta2)) #4000by26 x 26by10 = 4000by10\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    ynew = reparam_y(y,ol_sz,m)\n",
    "            \n",
    "    #Calculate cost function\n",
    "    Jtemp = (-ynew*np.log(a3))-((float(1)-ynew)*np.log(float(1)-a3)) #4000by10 \n",
    "    Jtemp2 = Jtemp.sum(axis=1).sum(axis=0)/m #sum over rows then columns, divide by m\n",
    "    #Add regularizing term, parameterized by lam\n",
    "    Reg_term = np.square(theta1[:,1:]).sum(axis=1).sum(axis=0) + np.square(theta2[:,1:]).sum(axis=1).sum(axis=0)\n",
    "    Reg_term = Reg_term*lam/(float(2*m))\n",
    "    J = Jtemp2 + Reg_term\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back propogation function\n",
    "args = (Xtrain_ab, ytrain_a, hl_size, ol_size, numsam, lam_reg)  # parameter values\n",
    "def backprop(x, *args):\n",
    "    thetas = x\n",
    "    X, y, hl_sz, ol_sz, m, lam = args\n",
    "    \n",
    "    #Reshape thetas\n",
    "    theta1 = thetas[0:hl_sz*(X.shape[1])].reshape((hl_sz,X.shape[1]))\n",
    "    theta2 = thetas[hl_sz*(X.shape[1]):].reshape((ol_sz,hl_sz+1)) \n",
    "    \n",
    "    # Initialize delta terms to 0\n",
    "    delsum_1=0\n",
    "    delsum_2=0\n",
    "    for i in range(0,m): #sum over the number of samples\n",
    "        a_1=np.transpose(X[i,:])\n",
    "        # Calculate layer 2\n",
    "        z_2 = np.matmul(X[i,:], np.transpose(theta1)) #1by401 times 401by25matrix -> 1by25\n",
    "        a_2 = sigmoid(z_2) #1by25\n",
    "        a_2 = np.transpose(a_2) #25by1\n",
    "        # Add bias term of ones\n",
    "        a_2 = np.concatenate((np.ones((1,)),a_2),axis=0) #26by1\n",
    "        # Calculate layer 3\n",
    "        z_3 = np.matmul(np.transpose(a_2),np.transpose(theta2)) #1by26 x 26by10 = 1by10\n",
    "        a_3 = np.transpose(sigmoid(z_3)) #10by1\n",
    "        \n",
    "        ynew = reparam_y(y,ol_sz,m)\n",
    "        \n",
    "        #Set delta for output layer\n",
    "        del_3=a_3-np.transpose(ynew[i,:]) #10 elements column vector \n",
    "        \n",
    "        #Sigmoid gradient, add 0; set-up for del2\n",
    "        sigGrad=np.concatenate((np.zeros((1,)),np.transpose(sigmoidgrad(z_2))),axis=0); #26by1\n",
    "        \n",
    "        #Delta 2\n",
    "        del_2=np.matmul(np.transpose(theta2),del_3)*sigGrad; #26by1\n",
    "        \n",
    "        #Sum the deltas; need to remove the bias unit\n",
    "        #reshape\n",
    "        delsum_1=delsum_1+np.matmul(del_2[1:].reshape((-1,1)),X[i,:].reshape((1, -1))) #25by1 x 1by401 -> 25by401\n",
    "        delsum_2=delsum_2+np.matmul(del_3.reshape((-1,1)),np.transpose(a_2).reshape((1,-1))) #10by26\n",
    "        \n",
    "    #Define gradients of theta - outside of for loop\n",
    "    theta1_grad=delsum_1/float(m); #25 by 401\n",
    "    theta2_grad=delsum_2/float(m); #10 by 26\n",
    "    #Regularized versions; don't do this for bias term\n",
    "    theta1_grad[:,1:]=theta1_grad[:,1:]+float(lam/m)*theta1[:,1:];\n",
    "    theta2_grad[:,1:]=theta2_grad[:,1:]+float(lam/m)*theta2[:,1:];\n",
    "    \n",
    "    return np.concatenate((theta1_grad.flatten(),theta2_grad.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.843900\n",
      "         Iterations: 15\n",
      "         Function evaluations: 30\n",
      "         Gradient evaluations: 30\n"
     ]
    }
   ],
   "source": [
    "# Optimize using fmin_cg optimizer\n",
    "#sio.optimize.fmin_cg\n",
    "optresult = optimize.fmin_cg(fpnn_cost,thetas_oned,fprime=backprop, args=(Xtrain_ab, ytrain_a, hl_size, ol_size, numsam, lam_reg),maxiter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25817466, -0.09112299, -0.06355436, ..., -1.1699625 ,\n",
       "        0.02387574, -1.38296919])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy of NN optimization\n",
    "def predict_nn(theta1, theta2, X, y, m, ol_sz):\n",
    "    temp1 = np.matmul(X,np.transpose(theta1)) #4000by401 x 401by25 -> 4000by25\n",
    "    h1 = sigmoid(temp1);\n",
    "    #Add bias term to h1\n",
    "    temp2 = np.concatenate((np.ones((h1.shape[0],1)),h1),axis=1) #4000by26\n",
    "    temp3 = np.matmul(temp2,np.transpose(theta2)) #4000by26 x 26by10 -> 4000by10\n",
    "    h2 = sigmoid(temp3);\n",
    "    \n",
    "    #Check accuracy\n",
    "    ind_max = h2.argmax(axis=1) # indices of the max of each row = class with highest probability\n",
    "    ind_max[ind_max == 0] = 10 #Convert back from 0 to 10\n",
    "    accur = np.mean(1*(ind_max == y))\n",
    "    return accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape thetas from opt_result\n",
    "theta1_r = optresult[0:hl_size*(Xtrain_ab.shape[1])].reshape((hl_size,Xtrain_ab.shape[1]))\n",
    "theta2_r = optresult[hl_size*(Xtrain_ab.shape[1]):].reshape((ol_size,hl_size+1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8915"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training accuracy\n",
    "predict_nn(theta1_r,theta2_r,Xtrain_ab,ytrain_a,numsam,ol_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bias term to Xcv_a\n",
    "Xcv_ab = np.concatenate((np.ones((Xcv_a.shape[0],1)),Xcv_a),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validation accuracy\n",
    "CVtest = predict_nn(theta1_r,theta2_r,Xcv_ab,ycv_a,ycv_a.size,ol_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy = 0.880\n"
     ]
    }
   ],
   "source": [
    "print ('CV Accuracy = %1.3f' % CVtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.843900\n",
      "         Iterations: 15\n",
      "         Function evaluations: 30\n",
      "         Gradient evaluations: 30\n",
      "Training Accuracy = 0.891\n",
      "CV Accuracy = 0.880\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.622616\n",
      "         Iterations: 25\n",
      "         Function evaluations: 53\n",
      "         Gradient evaluations: 53\n",
      "Training Accuracy = 0.929\n",
      "CV Accuracy = 0.915\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.539880\n",
      "         Iterations: 35\n",
      "         Function evaluations: 75\n",
      "         Gradient evaluations: 75\n",
      "Training Accuracy = 0.947\n",
      "CV Accuracy = 0.926\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.402210\n",
      "         Iterations: 70\n",
      "         Function evaluations: 155\n",
      "         Gradient evaluations: 155\n",
      "Training Accuracy = 0.981\n",
      "CV Accuracy = 0.929\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy as a function of iterations\n",
    "iters_test = [15, 25, 35, 70]\n",
    "Acc_re = np.zeros((4,2)) # Store accuracy results\n",
    "for i in range(0,4):\n",
    "    optresult = optimize.fmin_cg(fpnn_cost,thetas_oned,fprime=backprop, args=(Xtrain_ab, ytrain_a, hl_size, ol_size, numsam, lam_reg),maxiter=iters_test[i])\n",
    "    #Reshape thetas from opt_result\n",
    "    theta1_r = optresult[0:hl_size*(Xtrain_ab.shape[1])].reshape((hl_size,Xtrain_ab.shape[1]))\n",
    "    theta2_r = optresult[hl_size*(Xtrain_ab.shape[1]):].reshape((ol_size,hl_size+1)) \n",
    "    #Training accuracy\n",
    "    Acc_re[i,0] = predict_nn(theta1_r,theta2_r,Xtrain_ab,ytrain_a,numsam,ol_size)\n",
    "    #Cross-validation accuracy\n",
    "    Acc_re[i,1] = predict_nn(theta1_r,theta2_r,Xcv_ab,ycv_a,ycv_a.size,ol_size)\n",
    "    print ('Training Accuracy = %1.3f' % Acc_re[i,0])\n",
    "    print ('CV Accuracy = %1.3f' % Acc_re[i,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Digit Classification Neural Network')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy of NN predictions as a function of iterations \n",
    "cv_plotnn = plt.scatter(iters_test, Acc_re[:,1], label = 'cv')\n",
    "train_plotnn = plt.scatter(iters_test, Acc_re[:,0], label = 'train')\n",
    "plt.legend([train_plotnn, cv_plotnn], ['training set', 'cross-validation set'])\n",
    "\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Digit Classification Neural Network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
